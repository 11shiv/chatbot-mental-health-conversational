{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:11.472913Z",
     "iopub.status.busy": "2023-08-15T10:37:11.472499Z",
     "iopub.status.idle": "2023-08-15T10:37:11.492019Z",
     "shell.execute_reply": "2023-08-15T10:37:11.490872Z",
     "shell.execute_reply.started": "2023-08-15T10:37:11.472877Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:11.494640Z",
     "iopub.status.busy": "2023-08-15T10:37:11.493947Z",
     "iopub.status.idle": "2023-08-15T10:37:36.194252Z",
     "shell.execute_reply": "2023-08-15T10:37:36.193254Z",
     "shell.execute_reply.started": "2023-08-15T10:37:11.494596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\imshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.196450Z",
     "iopub.status.busy": "2023-08-15T10:37:36.195886Z",
     "iopub.status.idle": "2023-08-15T10:37:36.206160Z",
     "shell.execute_reply": "2023-08-15T10:37:36.204897Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.196397Z"
    }
   },
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.209316Z",
     "iopub.status.busy": "2023-08-15T10:37:36.208687Z",
     "iopub.status.idle": "2023-08-15T10:37:36.236997Z",
     "shell.execute_reply": "2023-08-15T10:37:36.235626Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.209276Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.239539Z",
     "iopub.status.busy": "2023-08-15T10:37:36.238643Z",
     "iopub.status.idle": "2023-08-15T10:37:36.250074Z",
     "shell.execute_reply": "2023-08-15T10:37:36.248944Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.239482Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    split sentence into array of words/tokens\n",
    "    a token can be a word or punctuation character, or number\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def stem(word):\n",
    "    \"\"\"\n",
    "    stemming = find the root form of the word\n",
    "    examples:\n",
    "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
    "    words = [stem(w) for w in words]\n",
    "    -> [\"organ\", \"organ\", \"organ\"]\n",
    "    \"\"\"\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    \"\"\"\n",
    "    return bag of words array:\n",
    "    1 for each known word that exists in the sentence, 0 otherwise\n",
    "    example:\n",
    "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
    "    \"\"\"\n",
    "    # stem each word\n",
    "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.252344Z",
     "iopub.status.busy": "2023-08-15T10:37:36.251813Z",
     "iopub.status.idle": "2023-08-15T10:37:36.329858Z",
     "shell.execute_reply": "2023-08-15T10:37:36.328473Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.252290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 patterns\n",
      "80 tags: ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n",
      "493 unique stemmed words: [\"'\", \"'d\", \"'depress\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', 'a', 'abil', 'about', 'absolut', 'accur', 'achiev', 'action', 'actual', 'advic', 'affect', 'afternoon', 'again', 'agre', 'alert', 'all', 'alon', 'alot', 'alreadi', 'alright', 'am', 'an', 'and', 'ani', 'anoth', 'answer', 'anxieti', 'anxiou', 'anymor', 'anyon', 'anyth', 'appear', 'appetit', 'apprehens', 'approach', 'architect', 'are', 'around', 'as', 'ask', 'at', 'attain', 'attent', 'au', 'avail', 'aw', 'awar', 'away', 'be', 'becaus', 'becom', 'been', 'befor', 'believ', 'better', 'between', 'bit', 'bonjour', 'boyfriend', 'break', 'bring', 'brother', 'brought', 'burn', 'by', 'bye', 'ca', 'call', 'can', 'capabl', 'capac', 'caught', 'caus', 'center', 'challeng', 'chanc', 'chang', 'characterist', 'cheer', 'child', 'choos', 'circl', 'clarifi', 'clear', 'close', 'commit', 'complet', 'concentr', 'concept', 'concern', 'condit', 'connect', 'consid', 'consum', 'continu', 'control', 'convers', 'could', 'coupl', 'crazi', 'creat', 'creation', 'creator', 'credit', 'cue', 'cure', 'curiou', 'current', 'dad', 'day', 'deal', 'deep', 'defin', 'definit', 'delv', 'depress', 'deserv', 'design', 'did', 'die', 'differ', 'discuss', 'disord', 'dispos', 'disrupt', 'do', 'doe', 'down', 'due', 'dumb', 'earli', 'edg', 'elabor', 'els', 'emot', 'empti', 'enough', 'entail', 'entir', 'even', 'exactli', 'exam', 'exampl', 'exist', 'experi', 'experienc', 'explain', 'explan', 'face', 'fact', 'famili', 'far', 'fare', 'fear', 'feasibl', 'feel', 'few', 'financi', 'find', 'fine', 'flag', 'focu', 'for', 'friend', 'frighten', 'from', 'function', 'gave', 'gear', 'genuin', 'get', 'girlfriend', 'give', 'go', 'good', 'goodby', 'grappl', 'grasp', 'great', 'group', 'grow', 'guess', 'guten', 'ha', 'had', 'hand', 'happen', 'happi', 'hard', 'hate', 'have', 'health', 'heart', 'heighten', 'hello', 'help', 'hey', 'hi', 'hint', 'hmmm', 'hola', 'how', 'howdi', 'i', 'if', 'ill', 'import', 'in', 'inclin', 'indic', 'individu', 'inquir', 'insominia', 'insomnia', 'intens', 'interest', 'into', 'involv', 'is', 'issu', 'it', 'jitteri', 'joke', 'just', 'k', 'keep', 'kill', 'kind', 'know', 'konnichiwa', 'lack', 'last', 'late', 'later', 'learn', 'leav', 'let', 'life', 'light', 'like', 'list', 'live', 'locat', 'lone', 'lot', 'made', 'maintain', 'make', 'manag', 'may', 'me', 'mean', 'meant', 'medic', 'medit', 'mental', 'mention', 'might', 'mind', 'mom', 'moment', 'money', 'mood', 'more', 'morn', 'much', 'muscl', 'my', 'myself', \"n't\", 'name', 'navig', 'need', 'nervous', 'new', 'nice', 'night', 'no', 'nobodi', 'not', 'note', 'noth', 'notic', 'now', 'odd', 'of', 'offer', 'oh', 'ok', 'okay', 'ola', 'on', 'one', 'onli', 'open', 'option', 'or', 'origin', 'out', 'outcom', 'outlin', 'over', 'overview', 'overwhelm', 'own', 'pass', 'past', 'peopl', 'perform', 'permit', 'person', 'pleas', 'point', 'pose', 'possess', 'possibl', 'potenti', 'practic', 'prefer', 'preoccupi', 'prepar', 'presenc', 'pretti', 'prevent', 'probabl', 'problem', 'profession', 'progress', 'prompt', 'proper', 'provid', 'purview', 'question', 'quiet', 'quit', 'race', 'rather', 'readi', 'realli', 'realm', 'recent', 'reckon', 'recov', 'recoveri', 'red', 'regain', 'relat', 'relationship', 'repeat', 'request', 'respons', 'revoir', 'right', 'rise', 'robot', 'room', 'sad', 'safeti', 'said', 'sake', 'say', 'sayonara', 'scare', 'see', 'seek', 'seem', 'sens', 'servic', 'share', 'shed', 'should', 'shut', 'sign', 'signal', 'signific', 'sister', 'situat', 'skill', 'sleep', 'slept', 'so', 'social', 'sole', 'some', 'someon', 'someth', 'sound', 'start', 'state', 'stay', 'steer', 'still', 'stress', 'strong', 'struggl', 'stuck', 'stupid', 'subject', 'such', 'suffer', 'suggest', 'suicid', 'support', 'suppos', 'sure', 'suspect', 'switch', 'symptom', 'tag', 'take', 'taken', 'talk', 'task', 'tell', 'telltal', 'tension', 'term', 'than', 'thank', 'that', 'the', 'thee', 'their', 'then', 'therapi', 'therapist', 'there', 'they', 'thi', 'thing', 'think', 'those', 'thought', 'through', 'time', 'to', 'today', 'told', 'topic', 'toward', 'treatment', 'troubl', 'trust', 'type', 'understand', 'uneas', 'unwel', 'up', 'upcom', 'use', 'useless', 'usual', 'veri', 'want', 'warn', 'wave', 'way', 'we', 'weigh', 'well', 'well-b', 'were', 'what', 'whatev', 'where', 'whi', 'which', 'whirlwind', 'who', 'whole', 'whom', 'whose', 'with', 'within', 'without', 'work', 'worri', 'worthless', 'would', 'wrong', 'ye', 'yeah', 'you', 'your', 'yourself']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))\n",
    "\n",
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.331737Z",
     "iopub.status.busy": "2023-08-15T10:37:36.331312Z",
     "iopub.status.idle": "2023-08-15T10:37:36.378204Z",
     "shell.execute_reply": "2023-08-15T10:37:36.376756Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.331688Z"
    }
   },
   "outputs": [],
   "source": [
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.380700Z",
     "iopub.status.busy": "2023-08-15T10:37:36.380272Z",
     "iopub.status.idle": "2023-08-15T10:37:36.394045Z",
     "shell.execute_reply": "2023-08-15T10:37:36.392797Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.380660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493 80\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.396065Z",
     "iopub.status.busy": "2023-08-15T10:37:36.395426Z",
     "iopub.status.idle": "2023-08-15T10:37:36.407272Z",
     "shell.execute_reply": "2023-08-15T10:37:36.406025Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.396028Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.411011Z",
     "iopub.status.busy": "2023-08-15T10:37:36.410029Z",
     "iopub.status.idle": "2023-08-15T10:37:36.469890Z",
     "shell.execute_reply": "2023-08-15T10:37:36.468232Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.410972Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:37:36.472098Z",
     "iopub.status.busy": "2023-08-15T10:37:36.471693Z",
     "iopub.status.idle": "2023-08-15T10:38:04.902955Z",
     "shell.execute_reply": "2023-08-15T10:38:04.901536Z",
     "shell.execute_reply.started": "2023-08-15T10:37:36.472062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1495\n",
      "Epoch [200/1000], Loss: 0.0053\n",
      "Epoch [300/1000], Loss: 0.0002\n",
      "Epoch [400/1000], Loss: 0.0001\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "final loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:38:11.018778Z",
     "iopub.status.busy": "2023-08-15T10:38:11.018303Z",
     "iopub.status.idle": "2023-08-15T10:38:11.028333Z",
     "shell.execute_reply": "2023-08-15T10:38:11.026812Z",
     "shell.execute_reply.started": "2023-08-15T10:38:11.018742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T10:38:18.382429Z",
     "iopub.status.busy": "2023-08-15T10:38:18.381982Z",
     "iopub.status.idle": "2023-08-15T10:41:27.650101Z",
     "shell.execute_reply": "2023-08-15T10:41:27.649021Z",
     "shell.execute_reply.started": "2023-08-15T10:38:18.382374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "You: Hi\n",
      "Medical ChatBot: Great to see you. How do you feel currently?\n",
      "You: I am sad\n",
      "Medical ChatBot: I'm here for you. Could you tell me why you're feeling this way?\n",
      "You: What can you do?\n",
      "Medical ChatBot: I'm here to provide general insights into anxiety and depression, address your mental health inquiries, and have pleasant chats. However, please recognize that I'm not a replacement for licensed mental health services. If you're seeking thorough assistance, I recommend connecting with a certified mental health professional.\n",
      "You: ok\n",
      "Medical ChatBot: Come Come elucidate your thoughts\n",
      "You: who created you\n",
      "Medical ChatBot: I was trained on a text dataset using Deep Learning & Natural Language Processing techniques\n",
      "You: i am feeling lonely\n",
      "Medical ChatBot: I'm sorry to hear that. I'm here for you. Talking about it might help. So, tell me why do you think you're feeling this way?\n",
      "You: I just dont know\n",
      "Medical ChatBot: Feeling preoccupied with exams is normal, but don't forget to manage your stress. Take small breaks, exercise, and engage in activities you enjoy to relax.\n",
      "You: Not exam related\n",
      "Medical ChatBot: I do not understand...\n",
      "You: It's not about exams\n",
      "Medical ChatBot: It's understandable that exams can dominate your thoughts. Make sure to prioritize self-care, sleep, and healthy study habits to maintain your well-being.\n",
      "You: you are wrong\n",
      "Medical ChatBot: Oh sorry I didn't realise that. I'll try not to repeat myself again.\n",
      "You: ok\n",
      "Medical ChatBot: How were you feeling last week?\n",
      "You: sad \n",
      "Medical ChatBot: How long have you been feeling this way?\n",
      "You: from last 3 weeks\n",
      "Medical ChatBot: I do not understand...\n",
      "You: Are you stupid?\n",
      "Medical ChatBot: I wish you wouldn't say such hurtful things. I'm sorry if I wasn't useful\n",
      "You: ok bye\n",
      "Medical ChatBot: Bye! Come back again.\n",
      "You: quit\n",
      "Medical ChatBot: It was great discussing this with you.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Medical ChatBot\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        print(bot_name + ': It was great discussing this with you.')\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
